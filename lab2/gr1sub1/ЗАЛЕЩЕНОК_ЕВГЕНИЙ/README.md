# Лабораторная работа №2: Продвинутые процессы Linux

**Студент:** Залещенок Евгений, 4 курс, 1 группа

### Цель работы
Уверенно работать с жизненным циклом процессов, реализовать обработку сигналов, научиться управлять планированием процессов с помощью `nice` и `CPU-affinity`, а также исследовать влияние ограничений на ресурсы процесса и интерпретировать системные метрики из `/proc`.

---
## Шаги и решения

### Часть A: Мини-супервизор с воркерами

#### Описание реализации
Был реализован набор скриптов на Bash:
*   `supervisor.sh`: Процесс-родитель, который запускает N воркеров, управляет их жизненным циклом, обрабатывает сигналы (`SIGTERM`, `SIGINT`, `SIGHUP`, `SIGUSR1`, `SIGUSR2`) и перезапускает упавших воркеров. Обработка завершенных дочерних процессов (`SIGCHLD`) реализована через цикл с командой `wait -n`.
*   `worker.sh`: Дочерний процесс, который имитирует полезную нагрузку в двух режимах ("тяжелом" и "легком"). Он корректно обрабатывает `SIGTERM` для завершения и `SIGUSR1`/`SIGUSR2` для смены режима работы.
*   `config.conf`: Файл конфигурации для задания количества воркеров и параметров режимов работы.
*   `run.sh`: Сценарий для демонстрации всех функциональных возможностей супервизора и воркеров.

#### Демонстрация работы
Ниже представлен полный лог выполнения скрипта `run.sh`, который демонстрирует все аспекты управления процессами.

```text
Супервизор запущен с PID: 9270. Наблюдайте за логами...
[SUPERVISOR 9270] Супервизор запущен.
[SUPERVISOR 9270] Запуск 3 воркеров...
[SUPERVISOR 9270] Воркер запущен с PID: 9272, 9273, 9274

---> Отправляем SIGUSR1 для переключения в 'легкий' режим
[SUPERVISOR 9270] Получен SIGUSR1
[WORKER 9272] [CPU fff] Переключение в 'легкий' режим (light)
...

---> Отправляем SIGUSR2 для возврата в 'тяжелый' режим
[SUPERVISOR 9270] Получен SIGUSR2
[WORKER 9272] [CPU fff] Переключение в 'тяжелый' режим (heavy)
...

---> Демонстрация 'graceful reload' через SIGHUP
[SUPERVISOR 9270] Получен SIGHUP. Перезапуск воркеров...
[WORKER 9272] [CPU fff] Получен SIGTERM, завершаю работу...
...
[SUPERVISOR 9270] Воркер запущен с PID: 9493, 9494, 9495

---> Демонстрация перезапуска при аварийном падении
Принудительно убиваем воркера с PID: 9493
[SUPERVISOR 9270] Воркер 9493 завершился с кодом 137.
[SUPERVISOR 9270] Перезапуск воркера...
[SUPERVISOR 9270] Новый воркер запущен с PID: 9539

---> Корректное завершение через SIGTERM
[SUPERVISOR 9270] Получен сигнал завершения. Отправка SIGTERM воркерам...
[WORKER 9494] [CPU fff] Получен SIGTERM, завершаю работу...
...
[SUPERVISOR 9270] Супервизор завершает работу.
Демонстрация завершена.
```

### Часть B: Планирование: nice и CPU-аффинити

#### Шаги выполнения
Для демонстрации влияния `nice` на планирование был проведен эксперимент:
1.  Два процесса, активно потребляющие CPU, были запущены одновременно и привязаны к одному ядру CPU (`taskset -c 0`) для создания конкуренции.
2.  С помощью `pidstat` были сняты метрики их производительности.
3.  Эксперимент был повторен, но для второго процесса было установлено значение `nice = +10`, что понижает его приоритет.

#### Результаты

**До применения `nice` (равный приоритет):**
В среднем оба процесса получали по ~50% CPU.

```
Linux 6.14.0-33-generic (zhenklchhhPC) 	10/05/2025 	_x86_64_	(12 CPU)

05:02:48 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
05:02:49 PM  1000      9622   50.00    0.00    0.00   50.00   50.00     0  bash
05:02:49 PM  1000      9623   50.00    0.00    0.00   50.00   50.00     0  bash

05:02:49 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
05:02:50 PM  1000      9622   50.00    0.00    0.00   50.00   50.00     0  bash
05:02:50 PM  1000      9623   50.00    0.00    0.00   50.00   50.00     0  bash

05:02:50 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
05:02:51 PM  1000      9622   50.00    0.00    0.00   50.00   50.00     0  bash
05:02:51 PM  1000      9623   50.00    0.00    0.00   50.00   50.00     0  bash

05:02:51 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
05:02:52 PM  1000      9622   50.00    0.00    0.00   50.00   50.00     0  bash
05:02:52 PM  1000      9623   50.00    0.00    0.00   50.00   50.00     0  bash

05:02:52 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
05:02:53 PM  1000      9622   50.00    0.00    0.00   50.00   50.00     0  bash
05:02:53 PM  1000      9623   50.00    0.00    0.00   50.00   50.00     0  bash

Average:      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
Average:     1000      9622   50.00    0.00    0.00   50.00   50.00     -  bash
Average:     1000      9623   50.00    0.00    0.00   50.00   50.00     -  bash
```
**После применения `nice = +10` ко второму процессу:**
Процесс с более высоким приоритетом получил ~99.8% CPU, а процесс с низким приоритетом — 0%.

```
Linux 6.14.0-33-generic (zhenklchhhPC) 	10/05/2025 	_x86_64_	(12 CPU)

05:03:20 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
05:03:21 PM  1000      9636   99.00    0.00    0.00    0.00   99.00     0  bash
05:03:21 PM  1000      9637    0.00    0.00    0.00    0.00    0.00    10  run.sh

05:03:21 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
05:03:22 PM  1000      9636  100.00    0.00    0.00    0.00  100.00     0  bash
05:03:22 PM  1000      9637    0.00    0.00    0.00    0.00    0.00    10  run.sh

05:03:22 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
05:03:23 PM  1000      9636  100.00    0.00    0.00    0.00  100.00     0  bash
05:03:23 PM  1000      9637    0.00    0.00    0.00    0.00    0.00    10  run.sh

05:03:23 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
05:03:24 PM  1000      9636  100.00    0.00    0.00    0.00  100.00     0  bash
05:03:24 PM  1000      9637    0.00    0.00    0.00    0.00    0.00    10  run.sh

05:03:24 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
05:03:25 PM  1000      9636  100.00    0.00    0.00    0.00  100.00     0  bash
05:03:25 PM  1000      9637    0.00    0.00    0.00    0.00    0.00    10  run.sh

Average:      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
Average:     1000      9636   99.80    0.00    0.00    0.00   99.80     -  bash
Average:     1000      9637    0.00    0.00    0.00    0.00    0.00     -  run.sh
```

---
## Ключевые выводы

1.  **Модель "супервизор-воркер"** является надежным способом управления группой процессов, обеспечивая их стабильную работу и автоматическое восстановление после сбоев.
2.  **Сигналы Linux** — мощный инструмент межпроцессного взаимодействия. Корректная обработка сигналов `SIGTERM`, `SIGHUP` и пользовательских сигналов (`SIGUSR1`/`SIGUSR2`) позволяет реализовать сложную логику управления, включая "graceful shutdown" и "graceful reload".
3.  **Приоритеты процессов (`nice`)** оказывают прямое и измеримое влияние на распределение процессорного времени планировщиком CFS только в условиях конкуренции за ресурсы.
4.  **CPU-аффинити (`taskset`)** — важный инструмент для оптимизации производительности, который позволяет явно управлять распределением нагрузки по ядрам и улучшать локальность кэша.

---
## Ответы на вопросы задания

**1. Чем процесс отличается от потока в Linux? Где это видно в `ps` и `/proc`?**

*   **Отличие:** Основное отличие — в управлении памятью. **Процесс** имеет собственное, изолированное адресное пространство. **Потоки** (threads) одного процесса разделяют общее адресное пространство (память, файловые дескрипторы), но имеют собственные стеки и регистры. Создание процесса (`fork`) дороже, чем создание потока (`clone`), из-за копирования адресного пространства.
*   **Как увидеть:**
    *   В `ps`: команда `ps -eLf` показывает потоки. У всех потоков одного процесса будет одинаковый `PID`, но разные `LWP` (Light Weight Process ID, он же TID - Thread ID).
    *   В `/proc`: Для процесса с PID `<pid>` существует директория `/proc/<pid>`. Внутри нее есть поддиректория `/proc/<pid>/task/`, где для каждого потока этого процесса создана своя директория с именем, равным его `TID`.

**2. Как `nice` влияет на планирование CFS? Какие есть пределы/исключения?**

*   **Влияние:** Значение `nice` (от -20 до +19) используется планировщиком CFS для определения "веса" процесса. Чем ниже `nice`, тем выше приоритет и вес. CFS распределяет процессорное время пропорционально весам всех активных процессов. Процесс с `nice = -20` получит значительно больше времени, чем процесс с `nice = +19`, при условии, что они оба хотят выполняться.
*   **Пределы и исключения:** `nice` влияет на распределение времени только для обычных политик планирования (`SCHED_NORMAL`). Он не влияет на процессы реального времени (`SCHED_FIFO`, `SCHED_RR`), которые всегда будут вытеснять обычные процессы. Эффект `nice` заметен только при **конкуренции за CPU**. Если процессор простаивает, даже процесс с `nice = +19` получит 100% доступного ему CPU.

**3. Что даёт CPU-аффинити и когда она вредна?**

*   **Что даёт:** CPU-аффинити (привязка процесса/потока к конкретным ядрам CPU) позволяет улучшить производительность за счет повышения эффективности кэширования. Когда процесс всегда выполняется на одном и том же ядре, его данные с большей вероятностью остаются в кэше этого ядра (L1/L2), что уменьшает задержки доступа к памяти. Это критично для высокопроизводительных и real-time приложений.
*   **Когда вредна:** Она может быть вредна, если используется неправильно. Жесткая привязка может привести к **несбалансированной нагрузке**, когда одни ядра перегружены, а другие простаивают. Это мешает системному планировщику, который обычно хорошо справляется с распределением нагрузки. Также, если привязать к одному ядру больше вычислительно-интенсивных потоков, чем оно может обработать, они будут мешать друг другу, вместо того чтобы выполняться параллельно на свободных ядрах.

**4. Чем отличаются `RLIMIT_AS`, `RLIMIT_DATA`, `RLIMIT_RSS`? Почему `RLIMIT_RSS` часто игнорируется?**

*   `RLIMIT_AS` (Address Space): Ограничивает общий объем **виртуальной памяти**, который может запросить процесс. Это самый распространенный и надежный лимит.
*   `RLIMIT_DATA`: Ограничивает размер сегмента данных (heap + BSS), т.е. память, выделенную через `brk()` и `sbrk()`.
*   `RLIMIT_RSS` (Resident Set Size): Ограничивает объем **физической памяти** (ОЗУ), который может занимать процесс.
*   **Почему `RLIMIT_RSS` игнорируется:** Ядру Linux очень сложно точно отслеживать и принудительно ограничивать RSS для отдельного процесса. Причины: общие библиотеки (shared libraries), которые используются многими процессами, но считаются в RSS каждого; страничная подкачка (swapping), когда страницы памяти могут выгружаться на диск и возвращаться. Управление физической памятью — это глобальная задача для ядра, и оно предпочитает использовать другие механизмы, такие как OOM Killer, когда память заканчивается во всей системе. Поэтому поддержка `RLIMIT_RSS` была признана неэффективной и в современных ядрах практически не работает.

**5. Почему возможны зомби и как их избежать при массовых рестартах воркеров?**

*   **Почему возможны:** Процесс-зомби — это завершенный дочерний процесс, запись о котором все еще хранится в таблице процессов. Он существует для того, чтобы родительский процесс мог прочитать его код завершения. Зомби появляются, когда родитель не вызывает системный вызов `wait()` или `waitpid()` для "сбора" информации о завершенном дочернем процессе.
*   **Как избежать:** Родительский процесс **обязан** обрабатывать сигнал `SIGCHLD`, который ядро посылает при завершении дочернего процесса. В обработчике этого сигнала нужно вызывать `wait()` или `waitpid()` в цикле, чтобы собрать статусы всех завершившихся детей. В нашем `supervisor.sh` эту роль выполняет цикл `while` с командой `wait -n`, которая ждет завершения любого дочернего процесса и позволяет супервизору отреагировать.

**6. Чем отличается «graceful shutdown» от «graceful reload/restart»? Какие последовательности безопасны?**

*   **Graceful Shutdown (корректное завершение):** Процесс получает сигнал (`SIGTERM`/`SIGINT`), перестает принимать новые задачи, завершает обработку текущих, освобождает ресурсы (закрывает файлы, сетевые соединения) и после этого завершается. Цель — не потерять данные и чисто выйти.
    *   *Безопасная последовательность:* `kill -SIGTERM <pid>` -> Процесс завершает текущие дела -> `exit()`.
*   **Graceful Reload/Restart (мягкая перезагрузка):** Процесс (обычно супервизор) обновляет свою конфигурацию или код без остановки обслуживания. Старые воркеры завершают обработку своих задач, в то время как новые воркеры, запущенные с новой конфигурацией, уже принимают новые задачи. Цель — нулевое время простоя (zero downtime).
    *   *Безопасная последовательность:* `kill -SIGHUP <supervisor_pid>` -> Супервизор запускает новых воркеров -> Супервизор посылает `SIGTERM` старым воркерам -> Старые воркеры завершают работу.

**7. Как повлияют контейнерные лимиты (cgroup v2) на наблюдаемые метрики процесса?**

Контейнерные лимиты, реализуемые через `cgroups v2`, обеспечивают более строгую и предсказуемую изоляцию, чем `ulimit`.
*   **CPU:** Если для cgroup установлен лимит CPU (`cpu.max`), то процессы внутри него не смогут потреблять больше указанной квоты. В `pidstat` или `top` мы увидим, что `%CPU` упирается в этот лимит. Также может появиться ненулевое значение `%steal` (stolen time), показывающее, сколько времени процесс хотел бы работать, но не мог из-за ограничений.
*   **Память:** Лимит `memory.max` работает гораздо надежнее, чем `RLIMIT_RSS`. Когда процессы в cgroup достигают этого лимита, будет вызван OOM Killer, который убьет процесс **внутри этого cgroup**, а не случайный процесс в системе. В `/proc/<pid>/status` появятся поля, относящиеся к cgroup, а метрики RSS будут строго ограничены. Это делает поведение системы под нагрузкой гораздо более предсказуемым.
---
## Как проверяли

Проверка работоспособности решения производилась комплексно с помощью автоматизированного сценария `run.sh` и системных утилит.

1.  **Автоматизированный тест:** Скрипт `run.sh` последовательно выполнял все ключевые сценарии:
    *   Запуск супервизора и создание N воркеров.
    *   Отправка `SIGUSR1`/`SIGUSR2` для проверки смены режимов.
    *   Отправка `SIGHUP` для проверки "graceful reload".
    *   Принудительное завершение одного из воркеров сигналом `SIGKILL` для проверки механизма автоматического перезапуска.
    *   Отправка `SIGTERM` для проверки "graceful shutdown" всей системы.
2.  **Анализ логов:** Корректность работы подтверждалась анализом консольного вывода, где в реальном времени отображались действия супервизора и реакция воркеров.
3.  **Измерение метрик:** Для части B (`nice` и affinity) использовалась утилита `pidstat`. Процессы принудительно привязывались к одному ядру с помощью `taskset` для создания явной конкуренции, что позволило чисто измерить эффект от изменения приоритета `nice`. Результаты измерений сохранялись в текстовые файлы для последующего анализа.
4.  **Ручная проверка:** Дополнительно выполнялись команды `ps aux | grep supervisor` и `pgrep -P <supervisor_pid>` для проверки иерархии процессов в разные моменты времени.

---
## Как использовали AI

При выполнении данной лабораторной работы использовался AI-ассистент (Google Gemini) в следующих ролях:

1.  **Генерация кода:** AI помог в создании первоначальных "каркасов" для скриптов `supervisor.sh` и `worker.sh` на основе детального описания требований из задания. Это ускорило начальный этап разработки.
2.  **Консультации:** AI использовался для получения быстрых ответов на синтаксические и концептуальные вопросы по Bash-скриптингу (например, "как правильно организовать цикл `wait` для обработки `SIGCHLD`" или "в чем разница между `kill` и `pkill`").
3.  **Структурирование отчета:** AI помог в первоначальном форматировании `REPORT.MD` и генерировании шаблонных разделов согласно требованиям.
4.  **Формулировка ответов:** Для теоретических вопросов AI предоставлял базовую информацию, которая затем была мной самостоятельно проверена, дополнена и переформулирована на основе результатов практических экспериментов и материалов курса.
