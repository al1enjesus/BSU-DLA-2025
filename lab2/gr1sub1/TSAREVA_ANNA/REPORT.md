Отчёт по лабораторной работе №2
Задание A: Мини-супервизор и рабочие процессы
Цель работы

Создать процесс-супервизор, который управляет группой дочерних процессов (воркеров): запускает их, корректно завершает, перезапускает при сбоях и меняет режимы их работы посредством сигналов.

Последовательность выполнения

Сборка и запуск программы

make run


Команда компилирует файлы supervisor.cpp и worker.cpp, после чего запускает главный процесс — супервизор.

Управление воркерами

Переключение в лёгкий режим — make light

Переключение в тяжёлый режим — make heavy

Перечтение конфигурации и перезапуск — make reload

Завершение всех процессов — make term

Проверка реакции на сбой воркера

pgrep worker
kill -9 <WORKER_PID>


После завершения воркера супервизор должен автоматически создать новый процесс.

Примеры вывода

При старте:

[SUP] System has 12 available CPU(s)
[SUP] Using default scheduling policy
[SUP] started worker 107207
[SUP] started worker 107208
[SUP] started worker 107209


Комментарий: Супервизор определяет количество доступных процессоров, устанавливает стратегию планирования и запускает несколько рабочих процессов.

Вывод воркеров:

PID=107207 mode=HEAVY tick=1 cpu=0 nice=0
PID=107208 mode=HEAVY tick=1 cpu=2 nice=0
PID=107209 mode=HEAVY tick=1 cpu=6 nice=0


Комментарий: Каждый воркер сообщает свой PID, текущий режим, номер CPU и значение nice. Воркеры распределены по разным ядрам.

После смены режима:

[SUP] switching workers to LIGHT
PID=108318 mode=LIGHT tick=13 cpu=2 nice=0
PID=108317 mode=LIGHT tick=13 cpu=7 nice=0
PID=108319 mode=LIGHT tick=13 cpu=4 nice=0


Комментарий: Супервизор передал всем воркерам сигнал переключения в лёгкий режим.

После перезагрузки конфигурации:

[SUP] reload config
[SUP] Using default scheduling policy
PID=107208 mode=HEAVY tick=20 cpu=6 nice=0
[WORKER 107208] exiting
...
[SUP] started worker 108317
[SUP] started worker 108318
[SUP] started worker 108319


Комментарий: Супервизор перечитал файл настроек и перезапустил всех рабочих с новыми параметрами.

При завершении воркера:

[SUP] worker 107207 exited
[SUP] started worker 107745


Комментарий: После неожиданного завершения воркера супервизор запустил новый процесс.

Завершение работы:

[SUP] shutting down...
[WORKER 108319] exiting
...
[SUP] worker 108317 exited
[SUP] worker 108318 exited
[SUP] worker 108319 exited


Комментарий: Завершение прошло корректно — супервизор последовательно остановил всех воркеров и завершил свою работу.

Итоги по заданию A

Созданный супервизор корректно управляет жизненным циклом рабочих процессов: выполняет их запуск, остановку, перезапуск и изменение режима. Обработка сигналов (SIGTERM, SIGHUP, SIGUSR1, SIGUSR2) и реакция на SIGCHLD обеспечивают стабильность и надёжность системы.

Повторение эксперимента

ОС: Linux (тестирование проводилось на Ubuntu 22.04)

Порядок действий:

Перейти в каталог проекта.

Выполнить make run.

Управлять воркерами командами make light, make heavy, make reload, make term.

Проверить авторестарт, завершив воркера через kill -9 <PID> и наблюдая реакцию супервизора.

Задание B: Планирование — nice и CPU affinity
Цель

Проанализировать влияние параметров nice и привязки к процессорам (CPU affinity) на распределение процессорного времени между воркерами.

Этапы выполнения

Настройка конфигурации (config.yaml):

Для теста CPU Affinity установить scheduling_policy: 2

Для теста nice — scheduling_policy: 1

Запуск эксперимента:

make run &
PIDS=$(pgrep -P $(pgrep supervisor))
pidstat -p $(echo $PIDS | tr ' ' ',') -u 1 10

Примеры результатов

Эксперимент 1: CPU Affinity (scheduling_policy: 2)

09:12:35 PM   UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
09:12:35 PM  1000    101986    0.00    0.00    0.00    0.00    0.00     0  worker
09:12:35 PM  1000    101987    0.00    0.00    0.00    0.00    0.00     1  worker
09:12:35 PM  1000    101988    0.00    0.00    0.00    0.00    0.00     2  worker


Комментарий: Каждый воркер выполняется только на закреплённом за ним ядре. Это подтверждает корректную работу sched_setaffinity.

Супервизор распределяет воркеров по ядрам циклически.

Поскольку в коде используется usleep(), CPU не нагружается, поэтому %CPU ≈ 0.

Привязка ограничивает доступные ядра, но не изменяет квоту времени процессора.

Эксперимент 2: Nice (scheduling_policy: 1)

PID=102200 mode=HEAVY tick=1 cpu=0 nice=10
PID=102201 mode=HEAVY tick=1 cpu=0 nice=0


Комментарий: Один воркер имеет nice=10, другой — nice=0. Это задаётся супервизором через setpriority().

Процессы с меньшим nice получают большую долю CPU.

В данном случае различие не видно из-за usleep(), но при активной нагрузке оно проявится.

Планировщик CFS распределяет время пропорционально “весу” процессов, вычисляемому на основе nice.

Итог по заданию B

Супервизор корректно применяет политику планирования, изменяя приоритеты (nice) и привязку к ядрам (affinity). Для реального анализа влияния этих параметров следует заменить usleep() на вычислительную нагрузку.

Повторение эксперимента

ОС: Linux (Ubuntu 22.04)

Действия:

Открыть src/config.yaml.

Задать scheduling_policy = 1 или 2.

Запустить make run &.

Собрать статистику с помощью pidstat.

Ответы на контрольные вопросы

Различия между процессом и потоком. Где это видно в ps и /proc?
Процесс имеет собственное адресное пространство и ресурсы. Потоки делят их между собой.
В ps -L отображаются и процессы, и потоки. В /proc/<pid>/task/ для каждого потока создаётся отдельная директория.

Как nice влияет на планирование CFS и каковы ограничения?
Значение nice варьируется от -20 (высший приоритет) до +19 (низший). Планировщик CFS распределяет время пропорционально приоритету. Обычный пользователь может только увеличивать nice, отрицательные значения доступны root.

Что даёт CPU affinity и в каких случаях это вредно?
Позволяет закрепить процесс за конкретным ядром, что уменьшает промахи кэша и даёт стабильную производительность.
Может быть вредна, если вызывает перегрузку отдельных ядер или мешает планировщику балансировать нагрузку.

Различия между RLIMIT_AS, RLIMIT_DATA, RLIMIT_RSS. Почему RLIMIT_RSS игнорируется?

RLIMIT_AS — ограничивает виртуальное адресное пространство.

RLIMIT_DATA — ограничивает размер сегмента данных.

RLIMIT_RSS — лимит на использование физической памяти, но ядро часто его игнорирует, управляя страницами самостоятельно.

Причины появления зомби-процессов и как их избежать.
Зомби появляются, если родитель не вызвал wait() для завершившегося потомка.
Решение — обрабатывать сигнал SIGCHLD и вызывать waitpid() до очистки всех дочерних процессов.

Отличие “graceful shutdown” от “graceful reload/restart”.

Shutdown — корректное завершение всех операций и выход.

Reload/Restart — перезапуск без потери состояния.
Безопасный порядок: при shutdown — SIGTERM, затем SIGKILL, при reload — запуск нового процесса до остановки старого.

Как cgroup v2 влияет на метрики процессов.
Cgroup может ограничивать CPU и память:

cpu.max ограничивает суммарную долю использования CPU.

memory.max ограничивает объём RAM, при превышении возможен OOM kill.
Метрики %CPU и RSS внутри cgroup будут соответствовать этим лимитам.