 
# Продвинутые процессы Linux: сигналы, планирование, ресурсы, /proc

## Цели
- Уверенно работать с жизненным циклом процессов: запуск, рестарт, корректное завершение.
- Реализовать обработку сигналов и протокол «graceful shutdown / reload».
- Управлять планированием: nice/приоритеты, CPU‑аффинити.

## Реализация
В качестве решения к лабораторной работе 2 представлено CLI приложение с возможностью контроля child процессов посредством IPC: Unix сигналов и SharedMemory.

Само приложение и особенности использования описаны в README.MD

Сценарий запуска и тестирования был следующий:
Запуск CLI
Выбор 1 - запуск воркеров
Выбор 3 - повторный запуск Light режима
Выбор 4 - запуск Heavy режима
Выбор 5 - перезагрузка конфига c новыми значениями кол-ва воркеров
Выбор 2 - остановка
Выбор 1 - запуск
Выбор 6 - выход

Логи тестирования зафиксированы в logs/demo.log

Из них можно заметить, что перезагрузка конфига не перезапускает процессы, в то же время контролирует кол-во воркеров. Изменение настроек по коду происходит через механиз SharedMemory. Child процессы по сигналу SIGHUP смотрят в SharedMemory и обновляют свои поля.

Старт/стоп работают корректно. Ввиду разделения периода busy на проверки каждую мс отклик происходит быстро.

Переходы между режимами так же происходятю Частота меняется.


## Ответы на вопросы к лабораторной работе 2:
# Linux процессы, потоки и управление ресурсами

## 1. Процесс vs поток
- **Процесс** — отдельное адресное пространство, файловые дескрипторы, сигналы и т.д.  
- **Поток (LWP)** — по сути тоже `task_struct`, но создан через `clone()` с флагами совместного использования (`CLONE_VM`, `CLONE_FILES`, `CLONE_SIGHAND` и др.).  
- **Где видно**:
  - `ps -eLf` или `ps -T -p <pid>` — потоки видны как строки с общим `PID`, но разными `LWP`.  
  - `/proc/<pid>/task/` — подкаталоги с TID каждого потока.  

---

## 2. Влияние `nice` на CFS
- Диапазон: **от –20 (высший приоритет) до 19 (низший)**.  
- CFS использует не `nice` напрямую, а **веса (weights)**:  
  - `nice -20` → вес ≈ 88761  
  - `nice 0` → вес ≈ 1024  
  - `nice 19` → вес ≈ 15  
  - Каждое изменение `nice` на +1 снижает вес примерно на 10%.  
- **Пределы и исключения**:
  - Пользователь без root может ставить только `nice ≥ 0`.  
  - `SCHED_FIFO` и `SCHED_RR` (real-time) не зависят от nice.  
  - `SCHED_IDLE` и `SCHED_BATCH` имеют особое поведение.  

---

## 3. CPU-аффинити
- **Что даёт**: ограничивает выполнение процесса/потока конкретными CPU → уменьшение кеш-промахов, предсказуемость работы.  
- **Когда вредно**:
  - Если потоки «зажаты» на мало ядер, а нагрузка высокая → простаивают другие CPU.  
  - Может мешать балансировке CFS и NUMA-политикам.  

---

## 4. RLIMIT_AS, RLIMIT_DATA, RLIMIT_RSS
- **`RLIMIT_AS`** — ограничение *виртуального адресного пространства* (включает mmap, стеки, кучу и т.д.).  
- **`RLIMIT_DATA`** — ограничение *heap* (сегмент `data + brk/sbrk`).  
- **`RLIMIT_RSS`** — ограничение *resident set size* (реально занятой RAM).  
  - На практике часто **игнорируется** ядром Linux, так как управление RSS отдано планировщику памяти и OOM-killer.  

---

## 5. Зомби-процессы
- **Почему возникают**: дочерний процесс завершился, но родитель ещё не сделал `wait()` → запись остаётся в таблице процессов.  
- **Как избежать**:
  - Родитель всегда делает `wait()` / `waitpid()`.  
  - Использовать `SIGCHLD` с `SA_NOCLDWAIT`.  
  - Массовые рестарты воркеров → организовать *reaper-процесс* (обычно init/systemd подчищает зомби).  

---

## 6. Graceful shutdown vs graceful reload/restart
- **Graceful shutdown**:
  - Завершаем приём новых запросов.  
  - Дожидаемся выполнения текущих.  
  - Освобождаем ресурсы.  
- **Graceful reload/restart**:
  - Старый процесс остаётся обслуживать существующих клиентов.  
  - Новый процесс загружается и принимает новые соединения.  
  - После завершения всех активных сессий старый процесс уходит.  
- **Безопасная последовательность**:
  1. Остановить приём новых соединений.  
  2. Запустить новый воркер.  
  3. Переключить трафик.  
  4. Дождаться завершения старого.  

---

## 7. Влияние cgroup v2 лимитов
- Контейнерные лимиты через **cgroup v2** влияют на наблюдаемые метрики:  
  - `memory.max` ограничивает доступную память (видно в `/sys/fs/cgroup/.../memory.current`).  
  - `cpu.max` и `cpu.weight` регулируют доступ к CPU (заметно в нагрузочных тестах).  
  - Внутри контейнера `top`, `ps`, `free` и др. могут показывать значения **не от хоста, а от cgroup-лимита** (например, доступно только 2ГБ, хотя у хоста 64ГБ).  
- Это приводит к тому, что метрики «изнутри контейнера» могут **не совпадать** с наблюдаемыми на уровне хоста.
