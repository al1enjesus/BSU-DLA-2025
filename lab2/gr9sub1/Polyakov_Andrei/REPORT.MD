##Лабораторная 2 — Продвинутые процессы Linux: сигналы, планирование, ресурсы, /proc

#Цель работы

Изучить механизмы управления процессами в Linux: разработать супервизор для набора воркеров, реализовать корректную обработку сигналов, продемонстрировать планирование процессов (nice, CPU-аффинити) и снять метрики загрузки CPU.

#Реализация

Все компоненты (supervisor.c, worker.c, Makefile, config.json, run.sh) написаны самостоятельно в рамках работы.

Воркеры реализуют два режима нагрузки (heavy/light), переключаемые сигналами.

Супервизор порождает N воркеров, корректно обрабатывает SIGTERM, SIGINT, SIGHUP, SIGUSR1, SIGUSR2 и убирает зомби.

run.sh автоматизирует сборку, запуск, генерацию нагрузки и снятие метрик.

#1. Supervisor и управление сигналами (критерий A)

Команда:
./run.sh

Наблюдения:

После запуска супервизор породил 4 воркера с разными nice и CPU-аффинити:
Starting supervisor...
supervisor pid=27358
[supervisor] spawned worker slot=0 pid=27360 nice=10 cpu=0
[supervisor] spawned worker slot=1 pid=27361 nice=10 cpu=1
[supervisor] spawned worker slot=2 pid=27362 nice=0 cpu=2
[supervisor] spawned worker slot=3 pid=27363 nice=0 cpu=3
[worker] pid=27361 id=1 starting heavy=9000/1000 light=2000/8000
[worker] pid=27360 id=0 starting heavy=9000/1000 light=2000/8000
[worker] pid=27362 id=2 starting heavy=9000/1000 light=2000/8000
[worker] pid=27363 id=3 starting heavy=9000/1000 light=2000/8000
List processes:
    PID COMMAND          NI
  27358 supervisor        0


При отправке SIGUSR2 нагрузка резко возросла: воркеры переключились в heavy-режим и каждый занимал ~89% CPU.

Linux 6.14.0-29-generic (AsusUbuntu) 	26.09.2025 	_x86_64_	(12 CPU)

03:05:51      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
03:05:52     1000      3474    0,00    0,99    0,00    0,00    0,99     4  firefox
03:05:52     1000     27360   89,11    0,00    0,00    0,00   89,11     0  worker
03:05:52     1000     27361   89,11    0,00    0,00    0,00   89,11     1  worker
03:05:52     1000     27362   89,11    0,00    0,00    0,00   89,11     2  worker
03:05:52     1000     27363   89,11    0,00    0,00    0,00   89,11     3  worker

При отправке SIGUSR1 воркеры переключились в light-режим, и загрузка снизилась до ~20% CPU.

Linux 6.14.0-29-generic (AsusUbuntu) 	26.09.2025 	_x86_64_	(12 CPU)

03:05:59      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
03:06:00     1000      2359    2,00    3,00    0,00    0,00    5,00     7  Xorg
03:06:00     1000      2647    4,00    2,00    0,00    0,00    6,00    11  gnome-shell
03:06:00     1000     20865    7,00    1,00    0,00    0,00    8,00     4  nautilus
03:06:00        0     26626    0,00    1,00    0,00    0,00    1,00     6  kworker/u48:2-kvfree_rcu_reclaim
03:06:00     1000     27360   20,00    0,00    0,00    0,00   20,00     0  worker
03:06:00     1000     27361   20,00    0,00    0,00    0,00   20,00     1  worker
03:06:00     1000     27362   20,00    0,00    0,00    0,00   20,00     2  worker
03:06:00     1000     27363   20,00    0,00    0,00    0,00   20,00     3  worker
03:06:00     1000     27371    0,00    1,00    0,00    0,00    1,00    10  pidstat

При отправке SIGHUP супервизор перечитал конфигурацию и перезапустил воркеров — это подтвердилось строками вида:
[supervisor] reload requested (SIGHUP)
[supervisor] loaded new config: workers=4 heavy=9000/1000 light=2000/8000

При завершении SIGTERM воркеры корректно завершились с сообщениями terminating gracefully, супервизор дождался их и закрылся.
[supervisor] graceful shutdown requested
[worker] pid=27361 id=1 terminating gracefully (iters=2488 total_work_us=11276035)
[worker] pid=27360 id=0 terminating gracefully (iters=2488 total_work_us=11276196)
[worker] pid=27363 id=3 terminating gracefully (iters=2484 total_work_us=11268048)
[worker] pid=27362 id=2 terminating gracefully (iters=2488 total_work_us=11276025)
[supervisor] timeout waiting for workers, sending SIGKILL
[supervisor] shutdown complete
Supervisor stopped


Вывод: супервизор корректно обрабатывает все необходимые сигналы и управляет воркерами.

#2. Планирование: nice и CPU-аффинити (критерий B)
Команда:
taskset -c 0 nice -n 0 ./worker --duration 5 &
PID1=$!
taskset -c 0 nice -n 10 ./worker --duration 5 &
PID2=$!
pidstat -u -p $PID1,$PID2 1 5

Наблюдения:

03:06:17      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
03:06:18     1000     27439   70,00    0,00    0,00   19,00   70,00     0  worker
03:06:18     1000     27440   24,00    0,00    0,00   69,00   24,00     0  worker

Оба воркера закреплены на одном ядре (taskset -c 0).

В выводе pidstat видно, что воркер с nice 0 получил около 70% CPU, а воркер с nice 10 только 24% CPU.

Такое распределение совпадает с ожиданиями: более низкий приоритет (больший nice) приводит к меньшей доле CPU-времени.

Вывод: разница в планировании процессов по приоритету подтверждается метриками, теория совпала с практикой.

##Ответы на вопросы

1. Чем процесс отличается от потока в Linux? Где это видно в ps и /proc?

Процесс имеет собственное адресное пространство, файловые дескрипторы, PID и независимую жизнь.

Потоки (POSIX threads, clone() с флагами CLONE_VM|CLONE_FILES|CLONE_SIGHAND) разделяют адресное пространство и ресурсы, но каждый поток имеет свой TID.

В ps потоки можно увидеть с ключами ps -L -p <pid> — будут показаны LWP (lightweight processes).

В /proc:

у процесса каталог /proc/<pid>;

у каждого потока внутри есть /proc/<pid>/task/<tid>.

2. Как nice влияет на планирование CFS? Какие есть пределы/исключения?

Планировщик CFS (Completely Fair Scheduler) делит CPU-время пропорционально «весу» задачи.

nice изменяет вес: nice = 0 → вес 1024 (базовый), nice = +5 → вес меньше, nice = –5 → вес больше.

Диапазон значений: от –20 (наивысший приоритет) до +19 (наименьший).

Исключения:

root может задавать отрицательный nice, обычный пользователь — только повышать (renice вверх).

Приоритеты SCHED_FIFO, SCHED_RR (реалтайм) не зависят от nice — CFS их не планирует.

3. Что даёт CPU-аффинити и когда она вредна?

Даёт: возможность закрепить процесс/поток за конкретным ядром (через sched_setaffinity, taskset). Это позволяет:

убрать миграции между ядрами (меньше кеш-промахов),

улучшить предсказуемость задержек.

Вредно:

при закреплении всех тяжёлых задач на одно ядро → недоиспользование остальных CPU;

если процесс интенсивно общается с другим, закреплённым на другом ядре (NUMA penalty).

4. Чем отличаются RLIMIT_AS, RLIMIT_DATA, RLIMIT_RSS? Почему RLIMIT_RSS часто игнорируется?

RLIMIT_AS — лимит виртуального адресного пространства (все маппинги, heap, mmap, stack).

RLIMIT_DATA — лимит только на размер сегмента данных (heap, brk()).

RLIMIT_RSS — лимит на резидентный набор страниц (фактическая память, RSS).

На практике RLIMIT_RSS почти не работает: ядро Linux игнорирует этот лимит, т.к. управление RSS делегировано подсистеме памяти/свопа (OOM killer, cgroups).

5. Почему возможны зомби и как их избежать при массовых рестартах воркеров?

Зомби возникают, когда дочерний процесс завершился, но родитель ещё не вызвал wait() — запись о процессе остаётся в таблице, пока не будет считан exit status.

При массовых рестартах воркеров супервизор обязан:

ловить сигнал SIGCHLD;

вызывать waitpid(-1, …, WNOHANG) в цикле, пока есть «трупы».

Если супервизор «потеряет» детей (не вызовет wait), таблица процессов переполнится.

6. Чем отличается «graceful shutdown» от «graceful reload/restart»? Какие последовательности безопасны?

Graceful shutdown: супервизор отправляет воркерам TERM, ждёт завершения запросов, потом выходит.

Graceful reload: супервизор перечитывает конфиг, порождает новых воркеров, затем аккуратно убивает старых (zero-downtime).

Безопасная последовательность:

Получить сигнал HUP.

Запустить новых воркеров.

Дождаться готовности (bind/listen).

Завершить старых.

Отличие: при reload сам супервизор остаётся жить.

7. Как повлияют контейнерные лимиты (cgroup v2) на наблюдаемые метрики процесса?

CPU: планирование внутри cgroup ограничено квотами/долями (cpu.max, cpu.weight). В pidstat процесс может «просить» больше CPU, но суммарно не выйдет за предел.

Память: лимиты (memory.max) задают верхнюю границу RSS/виртуалки. При превышении → OOM внутри контейнера, независимо от RLIMIT.

I/O: могут замедляться из-за io.max/io.weight.

Особенность: процессы внутри контейнера видят только свои лимиты (например, /proc/meminfo может показывать меньше памяти, чем реально на хосте).

#Воспроизводимость

Собрать проект:
make

Ручной запуск:

./supervisor &
посмотреть воркеров

ps -ef | grep worker
отправить SIGUSR1 всем воркерам (через супервизор)

kill -USR1 <supervisor_pid>
graceful reload

kill -HUP <supervisor_pid>
graceful shutdown

kill -TERM <supervisor_pid>

ИЛИ
скрипт с демонстрацией всех команд где достаточно поменять config:
bash run.sh

Выводы представлены в конце каждой подглавы



