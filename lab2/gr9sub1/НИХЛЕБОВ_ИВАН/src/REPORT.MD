# Лабораторная 2 — Продвинутые процессы Linux: сигналы, планирование, ресурсы, /proc

## Цель работы
Освоить управление процессами в Linux: супервизор с воркерами, обработка сигналов, корректное завершение (graceful shutdown), управление планированием и ресурсами, сбор метрик из /proc.

## Ход работы

### Часть A — Мини-супервизор с воркерами
1. Реализован процесс-супервизор (`supervisor.py`), который:
   - запускает N=3 воркеров,
   - отслеживает их завершение через `SIGCHLD`,
   - обрабатывает сигналы `SIGTERM`, `SIGINT`, `SIGHUP`, `SIGUSR1`, `SIGUSR2`.

2. Воркеры:
   - работают в двух режимах: **heavy** (много вычислений) и **light** (мало вычислений),
   - корректно завершаются по `SIGTERM`,
   - переключают режим по сигналам `SIGUSR1` и `SIGUSR2`.

3. Проверено:
   - при запуске run.sh  выводится:
     ``
     [Wouser@user-H510M-HDV:~/PycharmProjects/PythonProject$ ./run.sh
[Run] Запуск супервизора...
[Worker 9783] started in heavy mode
[Supervisor] started
[Worker 9784] started in heavy mode
[Worker 9785] started in heavy mode
[Run] Супервизор запущен с PID=9781
------ Текущие процессы supervisor/worker ------
UID          PID    PPID  C STIME TTY          TIME CMD
user        9783    9781 89 15:31 pts/1    00:00:01 python3 ./supervisor.py
user        9784    9781 90 15:31 pts/1    00:00:01 python3 ./supervisor.py
user        9785    9781 90 15:31 pts/1    00:00:01 python3 ./supervisor.py
[Run] Отправляем SIGHUP (перезапуск воркеров)...
[Supervisor] SIGHUP → reload config + restart workers
[Worker 9783] exiting gracefully
[Worker 9784] exiting gracefully
[Worker 9785] exiting gracefully
[Worker 9789] started in heavy mode
[Worker 9790] started in heavy mode
[Worker 9791] started in heavy mode
------ После перезапуска ------
UID          PID    PPID  C STIME TTY          TIME CMD
user        9789    9781 89 15:31 pts/1    00:00:01 python3 ./supervisor.py
user        9790    9781 89 15:31 pts/1    00:00:01 python3 ./supervisor.py
user        9791    9781 89 15:31 pts/1    00:00:01 python3 ./supervisor.py
[Run] Отправляем SIGTERM (завершение)...
[Supervisor] SIGTERM → shutting down workers
[Worker 9789] exiting gracefully
[Worker 9791] exiting gracefully
[Worker 9790] exiting gracefully
[Run] Супервизор завершил работу.
     ```
### B) Планирование: nice и CPU‑аффинити
Запускаем супервизор и воркеров :
python3 supervisor.py &
SUP_PID=$!
sleep 2

**Эксперимент:**

- Все воркеры закреплены на одно ядро (CPU 0) через `taskset -cp 0 <PID>`.
- Воркеры получили разные nice: 10077 → 0, 10078 → +10, 10079 → 0.
- Сняты метрики `pidstat -u 1 10 -p 10077,10078,10079`.

**Результаты:**

| PID   | Nice | CPU  | %CPU  | %wait |
|-------|------|------|-------|-------|
| 10077 | 0    | 0    | 47    | 44    |
| 10078 | 10   | 0    | 6     | 90    |
| 10079 | 0    | 0    | 47    | 44    |

**Выводы:**

- Процесс с большим nice (10078) почти не получает CPU при высокой конкуренции.  
- Процессы с одинаковым nice получают равные доли CPU.  
- CPU‑аффинити позволяет визуализировать влияние nice, «сжимая» конкуренцию на одно ядро.  
- При свободном CPU эффект nice почти не заметен (смотри предыдущий эксперимент).

D)Память и OOM

Для исследования поведения процесса при нехватке памяти был использован скрипт mem_test.py, имитирующий постепенное выделение памяти. Процесс запускался с ограничением виртуальной памяти через ulimit:
ulimit -v 1000000   # лимит виртуальной памяти ~1 GB
python3 mem_test.py & MEM_PID=$!

Наблюдение за потреблением памяти

Использовались команды pidstat и просмотр /proc/<pid>/status:
$ pidstat -r 1 10 -p 11367
Linux 6.14.0-29-generic (user-H510M-HDV) 	09/25/2025 	_x86_64_	(8 CPU)

04:21:36 PM   UID       PID  minflt/s  majflt/s     VSZ     RSS   %MEM  Command
04:21:37 PM  1000     11367   2442.00      0.00  440488  429620   1.31  python3
04:21:38 PM  1000     11367   2442.00      0.00  450256  439348   1.34  python3
...
04:22:02 PM  1000     11367   2442.00      0.00  684688  673844   2.06  python3
Average:     1000     11367   2442.00      0.00  640732  629850   1.92  python3

$ cat /proc/11367/status | head -20
Name:	python3
State:	S (sleeping)
VmPeak:	  792136 kB
VmSize:	  792136 kB
VmLck:	       0 kB
Системные метрики памяти на момент эксперимента:
$ free -h
               total        used        free      shared  buff/cache   available
Mem:            31Gi       6.3Gi        20Gi        50Mi       4.7Gi        24Gi
Swap:          8.0Gi          0B       8.0Gi
$ vmstat 1 10
procs -----------memory---------- ---swap-- -----io---- -system-- -------cpu-------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st gu
 0  0      0 20921364  94132 4803768    0    0   318   340 4904   10 19  1 79  1  0  0
Реакция на сигналы

SIGUSR1 – выделение дополнительного шага памяти.

SIGUSR2 – освобождение шага памяти.
Процесс корректно реагировал на сигналы, увеличивая/уменьшая потребление памяти ступенями.

Нехватка памяти

При достижении лимита виртуальной памяти (1 GB) процесс завершался аварийно (malloc возвращал ENOMEM), что демонстрирует работу механизма ulimit / RLIMIT_AS.
Выводы:

Ограничение ulimit -v эффективно предотвращает бесконтрольный рост процесса.

В реальных системах с большим количеством RAM и swap вызов OOM без лимита практически невозможен.

Сигналы SIGUSR1/2 позволяют динамически управлять потреблением памяти процесса.


Ответы на вопросы
1. Чем процесс отличается от потока в Linux? Где это видно в ps и /proc?

Процесс — это отдельная единица исполнения с собственным адресным пространством, таблицей открытых файлов и PID.

Поток (lightweight process, LWP) разделяет память и ресурсы с другими потоками того же процесса, но имеет собственный TID (thread ID).

В ps потоки можно увидеть через ps -Lf <pid> (LWP столбец).

В /proc/<pid>/task/ содержатся отдельные директории для каждого потока, указывая на их TID.

2. Как nice влияет на планирование CFS? Какие есть пределы/исключения?

nice задаёт приоритет процесса в планировщике CFS (Completely Fair Scheduler).

Более низкое значение (-20) → высокий приоритет, более высокое (19) → низкий приоритет.

Ограничения:

Пользователь без привилегий может повышать nice только в сторону снижения приоритета (>=0).

Только root может устанавливать отрицательные значения.

CFS использует nice для расчёта vruntime, влияя на частоту выделения CPU процессу.

3. Что даёт CPU‑аффинити и когда она вредна?

CPU‑аффинити фиксирует процесс на конкретных ядрах, снижая кэш‑промахи и миграцию потоков.

Полезно при высокой нагрузке на кэш или для real-time задач.

Вредно, если:

ядра перегружены, а другие простаивают → процесс недополучает CPU, падает суммарная производительность.


4. Чем отличаются RLIMIT_AS, RLIMIT_DATA, RLIMIT_RSS? Почему RLIMIT_RSS часто игнорируется?
Лимит	Описание
RLIMIT_AS	Максимальный размер виртуальной памяти (address space) процесса.
RLIMIT_DATA	Максимальный размер сегмента данных (heap) процесса.
RLIMIT_RSS	Максимальный размер resident set (физическая память).

5.Почему возможны зомби и как их избежать при массовых рестартах воркеров?

Зомби — это процесс, завершившийся, но с неполностью считанным статусом родительским процессом.

Возникает при отсутствии wait()/waitpid().

При массовых рестартах воркеров:

Использовать SIGCHLD + waitpid или автоматическое управление через systemd/supervisor.

В Python — subprocess.Popen(..., close_fds=True) и proc.wait().

6.Чем отличается «graceful shutdown» от «graceful reload/restart»? Какие последовательности безопасны?

Graceful shutdown — процесс корректно завершает все текущие задачи и освобождает ресурсы.

Graceful reload/restart — процесс перезапускает себя или дочерние воркеры без прерывания обслуживания (например, при обновлении конфигурации).

Безопасная последовательность:

Отказ от приёма новых соединений.

Завершение текущих задач.

Освобождение ресурсов и запуск нового экземпляра (reload).

7. Как повлияют контейнерные лимиты (cgroup v2) на наблюдаемые метрики процесса?

Лимиты cgroup v2 (memory.max, cpu.max) ограничивают видимую память и CPU процесса.

Метрики RSS/VSZ и vmstat/free будут отражать контейнерное ограничение, а не физическую систему.

При превышении лимита memory.max процесс получает OOM-kill, при cpu.max — процесс будет throttled.
