# Лабораторная 1* — Docker: анализ логов контейнеров

Курс: Проектирование приложений под Linux (DLA, 4 курс)

Цель версии со звездочкой — сохранить тему «анализ логов», но работать с логами контейнеров Docker и с более продвинутыми метриками (нормализация времени, агрегации, обнаружение всплесков). Лаба рассчитана на студентов, готовых к работе с пайплайнами Bash/awk/sed и воспроизводимостью.

## Что анализируем
- Логи контейнеров Docker:
  - Через `docker logs` (с отметками времени `--timestamps`).
  - Либо из JSON-файлов логов формата Docker json-file (фикстуры в `fixtures/`).
- Оба источника приводятся к единому CSV-формату для последующего анализа.

### Что такое "фикстуры"?
Фикстуры — это небольшие заранее подготовленные файлы логов, чтобы вы могли воспроизвести работу лабы без Docker/реального окружения. Они лежат в `lab1_star/fixtures/` и содержат примеры JSON-логов Docker. Запускаете анализ на них — получаете стабильный и одинаковый для всех результат.
Чтобы нарастить объём, добавлен генератор:
```bash
cd lab1_star/fixtures
make LINES=1500   # сгенерирует ≥1500 строк в каждом файле
```

## Структура каталога
```
lab1_star/
  README.md
  tools/
    run.sh          # основной запуск: сбор, нормализация, базовая аналитика
  fixtures/
    nginx-json.log  # пример JSON-логов Docker (json-file)
    app-json.log
  compose/
    docker-compose.yml
    app/
      Dockerfile
      app.py
    generate.sh     # поднимает стек и генерирует трафик, чтобы появились логи
  out/
    .gitkeep        # сюда складываются результаты
```

## Быстрый старт
```bash
# Вариант 1: фикстуры (самый простой и одинаковый для всех)
bash tools/run.sh --fixtures fixtures

# Вариант 2: локальный Docker (если установлен)
# 2.1) Поднять стек и сгенерировать немного трафика
bash compose/generate.sh
# 2.2) Собрать логи из контейнеров и проанализировать (пример с датой)
bash tools/run.sh --from-docker --since "2025-09-12 00:00" --until "2025-09-12 01:00"

# Фильтр по контейнерам (через запятую)
bash tools/run.sh --from-docker --containers "nginx,app"
```

Результаты появятся в `out/`:
- `docker_normalized.csv` — нормализованные строки (`ts_iso,container,stream,message`).
- `top_errors.csv` — топ контейнеров по ошибочным сообщениям.
- `bursts.csv` — всплески сообщений по минутам (бурсты).

## Задания (со звёздочкой)
А*) Сбор и нормализация
- Соберите логи за выбранный интервал либо из Docker (`--from-docker`), либо из фикстур (`--fixtures`).
- Приведите к CSV-формату: `ts_iso,container,stream,message`.
- Отсортируйте по времени. Сообщения нормализуйте (уберите перевод строки, замените запятые на пробелы).

Б*) Ошибки/инциденты
- Посчитайте топ-10 контейнеров по числу «ошибочных» сообщений (подстроки `error|fail|fatal|panic`, без учёта регистра).
- Сохраните в `out/top_errors.csv` с заголовком: `container,error_count`.

В*) Всплески (бурсты)
- Агрегируйте число сообщений поминутно по каждому контейнеру.
- Обнаруживайте всплески: текущая минута существенно выше среднего по предыдущим N минутам (по умолчанию N=30, множитель 3.0).
- Сохраните в `out/bursts.csv` с заголовком: `container,minute,count,baseline_avg,multiplier`.

Е*) (опционально) Корреляции
- Если есть «шумящие» контейнеры (например, nginx с 5xx), найдите минуты, где растёт доля `5xx` после перезапусков/деплоя.
- (Возможные источники: `docker ps --format`, `docker inspect` для restart count, `docker events`).

## Инструменты
- Требуется: `bash`, `awk`, `sed`, `sort`, `uniq`, `grep`.
- Опционально: `docker` (для реальных логов), `jq` или `python` (для парсинга JSON-файлов; скрипт имеет fallback и работает без них на фикстурах).

## Артефакты
- `out/docker_normalized.csv`
- `out/top_errors.csv`
- `out/bursts.csv`

## Проверка на фикстурах
```bash
bash tools/run.sh --fixtures fixtures
cat out/top_errors.csv | sed -n '1,10p'
cat out/bursts.csv | sed -n '1,10p'
```

Ожидается, что по фикстурам будут обнаружены:
- Ошибки у условного `nginx` (таймауты) и у `app` (ERROR событий несколько).
- Один-два заметных всплеска по минутам.

## Требования к отчёту (REPORT.MD у студента)
- Цель → Шаги/команды → Выводы → Ответы на вопросы → Как проверяли → Как использовали AI.
- Воспроизводимость: команды запуска и ожидаемые итоги на фикстурах.
- Безопасность: без `sudo rm -rf`, без опасных однострочников `curl | sh`.

## Подсказки
- Для `--from-docker` используйте `docker logs --timestamps --since ... --until ...`.
- Для JSON из `fixtures/` используйте парсинг через `jq` при наличии, либо fallback на встроенный awk/py в `tools/run.sh`.
- Аггрегации делайте по минутам: ключ `minute = substr(ts_iso,1,16)` для формата `YYYY-MM-DDTHH:MM`.


