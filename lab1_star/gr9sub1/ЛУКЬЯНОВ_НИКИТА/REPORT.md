# Отчёт по лабораторной работе 1* — Docker: анализ логов контейнеров

**Курс:** Проектирование приложений под Linux (DLA, 4 курс)
**Студент:** [Лукьянов Никита]

## Цель работы

Целью данной лабораторной работы является освоение методов сбора, нормализации и анализа логов контейнеров Docker. Работа направлена на развитие навыков работы с пайплайнами командной строки (Bash, `awk`, `sed`, `sort`), обработки временных рядов данных, обнаружения аномалий (всплесков активности) и агрегации статистики по ошибкам в распределенных системах.

## Шаги выполнения и использованные команды

### 1. Запуск анализа

Основной скрипт `run.sh` был запущен в режиме работы с фикстурами для получения стабильного и предсказуемого результата.

```bash
# Запуск основного скрипта анализа на фикстурах
bash tools/run.sh --fixtures fixtures
```

Данная команда инициирует выполнение всего пайплайна:
1.  **Задание А*:** Нормализация логов из фикстур с помощью `src/normalize_from_fixtures.sh`.
2.  **Задание Б*:** Подсчет топ-10 ошибок с помощью `src/compute_top_ten_errors.sh`.
3.  **Задание В*:** Обнаружение всплесков трафика с помощью `src/compute_burst.sh`.

Также скрипт был запущен для анализа Docker логов (после развёртывания контейнеров):

```bash
# Запуск основного скрипта анализа Docker логов
bash tools/run.sh --from-docker
```
Пайплайн остаётся тем же, за исключением того, что для анализа запускается скрипт `src/normalize_from_docker.sh`.

### 2. Просмотр результатов

После выполнения скрипта результаты были проверены.

```bash
# Просмотр нормализованных логов
head -n 5 out/docker_normalized.csv

# Просмотр топ-10 ошибок по контейнерам
cat out/top_errors.csv

# Просмотр обнаруженных всплесков
cat out/bursts.csv
```

В обоих случаях (на фикстурах и реальных логах) "бурстов" (аномалий) не было обнаружено, поэтому с помощью ИИ был сгенерирова файл `docker_burst_fixture.csv`, на котором и была проверена работа скрипта.

# Выводы

В ходе работы был успешно реализован и протестирован пайплайн для анализа логов Docker, состоящий из трех основных модулей.

## Задание А* (Сбор и нормализация)

Были разработаны два скрипта для нормализации логов из разных источников:

1.  **`normalize_from_docker.sh`** - для работы с реальными контейнерами через `docker logs`:
    - Реализован гибкий интерфейс с поддержкой фильтрации по времени (`--since`, `--until`) и контейнерам (`--containers`)
    - Временные метки извлекаются и сохраняются в стандартизированном формате
    - Поток (stdout/stderr) автоматически определяется на основе ключевых слов в сообщении
    - Выполняется очистка сообщений (удаление запятых для корректного CSV)

2.  **`normalize_from_fixtures.sh`** - для работы с фикстурами в JSON-формате:
    - Используется `jq` для эффективного парсинга структурированных логов
    - Имя контейнера извлекается из имени файла
    - Выполняется нормализация и экранирование специальных символов
    - Обеспечивается сортировка по временным меткам для временной согласованности

**Результат:** Оба скрипта успешно преобразуют разнородные источники логов в единый CSV-формат (`ts_iso,container,stream,message`), готовый для последующего анализа.

## Задание Б* (Ошибки/инциденты)

Скрипт **`compute_top_ten_errors.sh`** продемонстрировал эффективную работу:
- Реализован поиск ошибок по ключевым паттернам (`error|fail|fatal|panic`) с игнорированием регистра
- Выполняется агрегация ошибок по контейнерам с подсчетом количества
- Результаты сортируются по убыванию количества ошибок
- Сохраняются только топ-10 контейнеров с наибольшим числом ошибок

**Результат:** Сформирован четкий рейтинг проблемных контейнеров, что позволяет оперативно выявлять наиболее критические компоненты системы.

## Задание В* (Всплески)

Скрипт **`compute_bursts.sh`** реализовал продвинутый алгоритм обнаружения аномалий:
- Выполняется поминутная агрегация количества сообщений для каждого контейнера
- Реализован алгоритм скользящего среднего с настраиваемым окном (по умолчанию 30 минут)
- Обнаруживаются всплески, где текущая активность превышает среднее значение в заданное число раз (по умолчанию 3.0)
- Сохраняется детальная информация о каждом всплеске: контейнер, минута, количество сообщений, базовый уровень и множитель

**Результат:** Система эффективно выявляет аномальные периоды активности, что критически важно для мониторинга производительности и обнаружения инцидентов в реальном времени.

## Как проверялась работа

1.  **Воспроизводимость на фикстурах:** Основной метод проверки. Запуск `bash tools/run.sh --fixtures fixtures` всегда давал один и тот же ожидаемый результат в папке `out/`. Это подтверждает корректность алгоритмов и детерминированность скриптов.
2.  **Проверка формата выходных данных:** Файлы `docker_normalized.csv`, `top_errors.csv` и `bursts.csv` были проверены на соответствие требуемому формату (наличие заголовков, корректность разделителей, валидность данных) с помощью команд `head`, `cat` и `wc -l`.
3.  **Валидация логики:** На примере сгенерированных фикстур был проведен ручной подсчет нескольких ошибок для проверки корректности работы скрипта `compute_top_ten_errors.sh`. Логика обнаружения всплесков также была верифицирована на небольшом искусственном наборе данных (`fixtures/docker_burst_fixture.csv`).

## Как использовался AI

Искусственный интеллект (ChatGPT/DeepSeek) был использован на различных этапах работы для повышения эффективности:

1.  **Генерация тестовых данных:** ИИ помог быстро создать специальный файл `docker_burst_fixture.csv` с заранее запрограммированными всплесками для точной проверки алгоритма детектирования аномалий.

2. **Изучение документации утилит:** ИИ использовался для изучения таких утилит как jq, awk и sort. Писались запросы по типу: "Расскажи про синтаксис awk", "Подробно опиши, что делает данная команда", "Расскажи, что значит флаг -nr у sort" и тому подобные.

3.  **Документирование:** ИИ ассистировал в структурировании данного отчета, предложив четкий шаблон и формулировки для описания целей и выводов.

**Важно:** Весь предложенный AI код был тщательно проверен, осмыслен и адаптирован под конкретные нужды проекта. ИИ использовался как инструмент для ускорения разработки, а не для ее полного выполнения.
