# Лабораторная работа 1
---
## Задание А: Частотный анализ слов в syslog (TOP-5)

#### Цель
Определить 5 самых часто встречающихся слов в системном журнале `/var/log/syslog`. Для корректного подсчёта необходимо было привести все слова к нижнему регистру (нормализовать) и отделить их от знаков препинания и прочих символов.

---
#### Шаги/решения
Для решения задачи был использован конвейер (pipeline) из стандартных утилит командной строки Linux. Логика решения была следующей:
1.  Прочитать содержимое лог-файла.
2.  Очистить текст, оставив только буквы и цифры, и разместить каждое слово на новой строке.
3.  Привести все слова к единому регистру (нижнему).
4.  Отсортировать слова для последующего подсчёта.
5.  Подсчитать количество вхождений каждого уникального слова.
6.  Отсортировать результат по убыванию количества.
7.  Вывести первые 5 строк результата.

**Итоговая команда:**
```bash
cat /var/log/syslog | tr -cs '[:alnum:]' '\n' | tr '[:upper:]' '[:lower:]' | sort | uniq -c | sort -nr | head -n 5
```
---
#### Выводы
В результате выполнения команды был получен следующий список из 5 самых частых "слов" и их количества:
   3374 00
   3263 2025
   3243 03
   3205 09
   3194 zhenklchhhpc
Наиболее частыми элементами в логе являются числовые значения (00, 2025, 03, 09), которые, скорее всего, являются частями временных меток (timestamp), дат или служебных сообщений. Также в ТОП-5 попало имя хоста (zhenklchhhpc).

---
#### Как проверяли
Я проверял корректность работы конвейера поэтапно. Вместо того чтобы запускать всю команду сразу, я добавлял каждый её сегмент последовательно, анализируя промежуточный результат. Для просмотра вывода на каждом шаге я использовал конструкцию `| head`.

1.  Сначала я выполнил `cat /var/log/syslog | tr -cs '[:alnum:]' '\n' | head`, чтобы убедиться, что текст корректно разбивается на отдельные слова, расположенные на новых строках.
2.  Затем я добавил команду для нормализации регистра: `... | tr '[:upper:]' '[:lower:]' | head`. Я проверил, что все заглавные буквы в выводе были преобразованы в строчные.
3.  После этого я последовательно добавил и проверил работу `sort`, `uniq -c` и, наконец, `sort -nr`.

Этот пошаговый подход позволил мне полностью контролировать процесс обработки данных и быть уверенным, что итоговый результат верен, а каждая утилита в конвейере работает так, как и ожидалось.

---
#### Как использовал AI
Искусственный интеллект (AI-ассистент Gemini) был использован для следующих целей:
1.  Получения детального пошагового объяснения каждой утилиты (`tr`, `sort`, `uniq`) и её флагов в предложенном конвейере.
2.  Структурирование данного отчета в полном соответствии с предоставленными требованиями к оформлению.

----
## Задание Б: Неудачные попытки входа (auth.log)

#### Цель
Определить ТОП-10 IP-адресов (с замаскированным последним октетом), с которых происходили неудачные попытки входа, на основе анализа файла `/var/log/auth.log`.

---
#### Шаги/решения
Для поиска информации о неудачных попытках входа была использована следующая команда. Она находит строки со словами "Failed" или "Invalid", извлекает из них IP-адреса, маскирует последний октет, а затем подсчитывает и сортирует их для выявления ТОП-10.

**Итоговая команда:**
```bash
grep -E 'Failed|Invalid' /var/log/auth.log | grep -oE '[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}' | sed -E 's/(\d+\.\d+\.\d+\.)\d+/\1x/g' | sort | uniq -c | sort -nr | head -n 10
```
---
#### Выводы
В анализируемом файле /var/log/auth.log отсутствуют записи о неудачных (Failed) или недействительных (Invalid) попытках входа в систему за период, который охватывает данный лог. Система не подвергалась таким атакам, или они не были зафиксированы. В результате выполнения команды не было получено никакого вывода.

---

#### Как проверял
Я запустил полную команду и убедился, что она не возвращает ошибок, а просто выдаёт пустой результат. Для дополнительной проверки я выполнил первую часть команды (grep -E 'Failed|Invalid' /var/log/auth.log) отдельно и подтвердил, что она также ничего не находит. Это доказывает, что в исходном файле нет данных для анализа. Также проверил содержимое файла.

---

#### Как использовал AI
Искусственный интеллект (AI-ассистент Gemini) был использован для:
1.  Объяснения принципа работы предложенного конвейера команд.
2.  Интерпретации результата (почему вывод команды оказался пустым).
3.  Помощи в корректном оформлении этого результата в итоговом отчёте.

----
## Задание В: Установки пакетов (dpkg.log)

#### Цель
Выявить ТОП-10 самых часто устанавливаемых пакетов на основе анализа лог-файла менеджера пакетов Debian `/var/log/dpkg.log`.

---
#### Шаги/решения
Для решения этой задачи был применён конвейер команд. Его логика заключалась в следующем: сначала отфильтровать в логе только строки, относящиеся к установке пакетов (событие `install`). Затем из этих строк извлечь и очистить имена пакетов. На последнем этапе провести их подсчёт, сортировку по частоте и вывести 10 самых популярных.

**Итоговая команда:**
```bash
grep ' install ' /var/log/dpkg.log | awk '{print $4}' | cut -d: -f1 | sort | uniq -c | sort -nr | head -n 10
```

---

#### Выводы
При выполнении данной команды вывод какого-либо результата отсутствовал. в файле `/var/log/dpkg.log` не было найдено ни одной строки, содержащей событие ` install `. Это говорит о том, что за период времени, который охватывает лог, в системе не производилась установка новых пакетов с помощью `dpkg` или `apt`.

---
#### Как проверял
Проверил содержимое файла, он оказался пустым. Чтобы убедиться, что проблема не в ошибке конвейера, я выполнил его первую и самую важную часть отдельно: `grep ' install ' /var/log/dpkg.log`

---

#### Как использовал AI
Искусственный интеллект (AI-ассистент Gemini) был использован для следующих целей:
1.  Получения пошагового объяснения работы команд `awk` и `cut` в составе конвейера.
2.  Интерпретации полученного пустого вывода как валидного результата.
3.  Помощи в структурировании и написании данного отчёта в формате Markdown.






