# Лабораторная работа 6: работы с файловыми системами FUSE

## Цель работы
Изучить архитектуру виртуальной файловой системы (VFS) Linux и научиться создавать пользовательские файловые системы с использованием FUSE (Filesystem in Userspace). Понять принципы работы файловых операций, взаимодействие между ядром и userspace, а также оценить производительность userspace файловых систем.

## Данные среды
- OS: Linux Debian 12 (Bookworm)
- Libs: libfuse3-dev для FUSE
- BS: Make

## Теория
### Virtual File System (VFS)

VFS — это абстрактный слой в ядре Linux, который предоставляет единый интерфейс для работы с различными файловыми системами (ext4, btrfs, NFS, FUSE и т.д.). VFS позволяет приложениям использовать одни и те же системные вызовы (open(), read(), write()) независимо от типа файловой системы.

### Ключевые структуры VFS:

    superblock — описывает файловую систему в целом (размер блока, root inode)
    inode — метаданные файла (размер, права, временные метки)
    dentry — кеш имен директорий (связывает имя файла с inode)
    file — открытый файл (file descriptor, позиция чтения)

### FUSE (Filesystem in Userspace)
FUSE позволяет создавать файловые системы в userspace без написания кода для ядра. Драйвер FUSE в ядре перенаправляет VFS операции в userspace процесс через специальный протокол.

### Преимущества FUSE:
- Разработка в userspace (проще отладка, нет риска kernel panic)
- Можно использовать обычные библиотеки (libcurl, libarchive)
- Безопасность (ошибка не роняет систему)

### Недостатки FUSE:
- Overhead на context switch между kernel и userspace (медленнее на 20-40%)
- Дополнительное копирование данных через kernel/userspace boundary

### Как работает (порядок вызовов)
```
1. Bash команда "cat"
   ↓
2. cat вызывает open("/mnt/fuse/test.txt")
   ↓
3. Системный вызов (syscall) попадает в ядро Linux
   ↓
4. VFS (Virtual File System) в ядре видит путь /mnt/fuse/
   ↓
5. VFS проверяет: какая ФС смонтирована в /mnt/fuse?
   ↓
6. VFS находит: "О! Это FUSE filesystem"
   ↓
7. FUSE драйвер в ядре перенаправляет запрос через /dev/fuse
   ↓
8. libfuse в userspace получает запрос
   ↓
9. libfuse вызывает вашу функцию passthrough_open()
   ↓
10. Ваш код выполняет реальный open(/tmp/source/test.txt)
   ↓
11. Результат возвращается обратно по цепочке
   ↓
12. cat получает file descriptor и читает данные
```

## Общая информация по реализации решения к поставленным задачам
Задание A выполнено в passthrough.c
Задание B выполнено в rot13_fs.c
Задание C выполнено в uppercase.c

- Все тестировалось с помощью скрипта test.sh. Инструкция к его использованию присутствует как часть README.MD
- Все логи (выводы тестирования) сохранены в logs/ директорию.
- В логи входит все выводы самого скрипта, а так же вывод fuse3, который требовался в описании задания.
- В качестве директории-источника была выбрана "/tmp/fuse_test_source", которая монтируется в точку "/tmp/ fuse_test_mount". fuse_test_source заранее создана с нужными файлами. Она создавалась автоматически через test.sh. Вывод шага подготовки директорий и монтирования можно увидеть в logs/preparation_output.txt
- Перед каждым запуском тестов исполнялся cleanup директорий.

## Задание A (Общее)
В задании было необходимо примонтировать FUSE FS и показать влияние изменений в монтированной директории на директорию-источник. 

Было произведено два теста:
- Проверка монтирования через чтение файла.
- Создание нового файла, проверка его появления в директории-источнике через ls.

Лог файл: logs/task1_output.txt

## Задание B (Вариант 2)
В задании B для варианта 2 было предложено сделать FUSE систему с шифрованием. При чем так, чтобы при использовании дефолтного чтения файла он был шифрован, а при использовании fuse-открытия - расшифрованным.

Было произведен тест:
- Запись 'Secret Message' в secret.txt
- Чтение из монтированной директории (должно было быть расшифрованным)
- Чтение из директории-источник (должно было быть зашифрованным)

Тест был пройден
Логфайл: logs/task2_output.txt

## Задание C (Вариант 2)
В задании C для варианта 2 было предложено сделать FUSE систему с преобразованием любого текста к заглавным.
Тест был проведен по аналогии с B, т.е. создание, чтение в FUSE, чтение в source. Заглавные в FUSE, исходные в source

Тест был пройден
Логфайл: logs/task3_output.txt

## Benchmark 
Бенчмарк так же был собран по предложенной в задании схеме и изложен в logs/perfomance_benchmark_output.txt

### Методика

Для оценки производительности был проведен benchmark последовательного чтения файла размером 10 MB. Использовалась утилита `dd` с размером блока 4096 байт. Тестовый файл располагался в `/tmp/fuse_test_source` (tmpfs).

Измерялись три варианта:
- Прямое чтение из source директории (baseline)
- Чтение через Passthrough FUSE
- Чтение через Uppercase FUSE

### Результаты

| Метод | Throughput | Время 
| Direct (native) | 4.1 GB/s | 0.004s |
| Passthrough FUSE | 1.4 GB/s | 0.009s |
| Uppercase FUSE | 436 MB/s | 0.028s |

### Анализ

Native чтение: 4.1 GB/s - максимальная производительность при прямом чтении из tmpfs без каких-либо промежуточных слоев.

Passthrough FUSE: 1.4 GB/s (падение на 66%). Основные причины overhead:
- Context switch между kernel и userspace при каждой операции FUSE
- Копирование данных через kernel/userspace boundary
- Протокол FUSE добавляет накладные расходы на каждый системный вызов
- Множественные GETATTR вызовы для проверки метаданных

Из логов видно, что система делает проверки метаданных и постепенно увеличивает размер буфера чтения от 16KB до 128KB, что является стандартным поведением read-ahead механизма.

Uppercase FUSE: 436 MB/s (падение на 89%). Помимо базового overhead от FUSE, добавляется:
- CPU-время на преобразование каждого байта через `toupper()`
- Дополнительные операции в цикле по всему буферу данных
- Логирование каждой трансформации (80 операций по ~128KB)

В логах четко видны вызовы `[TRANSFORM] Converted N bytes to uppercase` на каждую операцию чтения, что подтверждает активную обработку данных.

### Выводы по нагрузочному тестированию

Результаты демонстрируют ожидаемое поведение FUSE файловых систем:
- Базовый overhead FUSE составляет примерно 66% от native производительности
- Дополнительная обработка данных (uppercase преобразование) добавляет еще ~23% overhead
- Для операций с большими файлами overhead от context switching становится критическим фактором
- CPU-интенсивные преобразования данных значительно снижают throughput

Полученные результаты соответствуют типичному поведению userspace файловых систем, где удобство разработки и гибкость достигаются за счет производительности.
